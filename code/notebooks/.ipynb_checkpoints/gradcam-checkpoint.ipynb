{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d94731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports here\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from argparse import Namespace\n",
    "import sys\n",
    "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, EigenGradCAM, LayerCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# own code\n",
    "sys.path.append('../')\n",
    "from datasets import MyopsDataset2D, DeepRiskDataset2D\n",
    "from resnet import LightningResNet\n",
    "from simplenet import LightningSimpleNet\n",
    "from drn import LightningDRN\n",
    "from preprocessing import set_image_range, normalize_image\n",
    "from convnext import LightningConvNeXt\n",
    "from train_classifier_2d import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246ccaf",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424649a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningDRN(\n",
       "  (feature_dropout_layer): Dropout2d(p=0.0, inplace=False)\n",
       "  (cam_dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "  (classifier): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (final_pool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "  (up_bilinear): UpsamplingBilinear2d(scale_factor=8.0, mode=bilinear)\n",
       "  (up_conv_transpose): ConvTranspose2d(1, 1, kernel_size=(16, 16), stride=(8, 8), padding=(4, 4), bias=False)\n",
       "  (output2pred): Sigmoid()\n",
       "  (train_accuracy): Accuracy()\n",
       "  (validation_accuracy): Accuracy()\n",
       "  (test_accuracy): Accuracy()\n",
       "  (train_confusion): ConfusionMatrix()\n",
       "  (validation_confusion): ConfusionMatrix()\n",
       "  (test_confusion): ConfusionMatrix()\n",
       "  (train_auroc): AUROC()\n",
       "  (validation_auroc): AUROC()\n",
       "  (test_auroc): AUROC()\n",
       "  (train_pr_curve): PrecisionRecallCurve()\n",
       "  (validation_pr_curve): PrecisionRecallCurve()\n",
       "  (test_pr_curve): PrecisionRecallCurve()\n",
       "  (train_roc): ROC()\n",
       "  (validation_roc): ROC()\n",
       "  (test_roc): ROC()\n",
       "  (train_auc): AUC()\n",
       "  (validation_auc): AUC()\n",
       "  (test_auc): AUC()\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer7): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer8): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load a trained model\n",
    "drnd24 = LightningDRN(depths=[1, 1, 2, 2, 2, 2, 2, 2], arch=\"D\", num_classes=1, in_chans=1)\n",
    "drnd24.load_state_dict(torch.load(r\"..\\..\\tb_logs\\drnd\\version_7\\checkpoints\\epoch=79-step=12079.ckpt\", map_location=torch.device('cpu'))['state_dict'])\n",
    "drnd24.eval()\n",
    "\n",
    "drnd24_120epochs = LightningDRN(depths=[1, 1, 2, 2, 2, 2, 2, 2], arch=\"D\", num_classes=1, in_chans=1)\n",
    "drnd24_120epochs.load_state_dict(torch.load(r\"..\\..\\tb_logs\\drnd\\version_8\\checkpoints\\epoch=119-step=18119.ckpt\", map_location=torch.device('cpu'))['state_dict'])\n",
    "drnd24_120epochs.eval()\n",
    "\n",
    "drnd24_maxpool = LightningDRN(depths=[1, 1, 2, 2, 2, 2, 2, 2], arch=\"D\", num_classes=1, in_chans=1, pooling=\"max\")\n",
    "drnd24_maxpool.load_state_dict(torch.load(r\"..\\..\\tb_logs\\drnd_maxpool\\version_1\\checkpoints\\epoch=119-step=18119.ckpt\", map_location=torch.device('cpu'))['state_dict'])\n",
    "drnd24_maxpool.eval()\n",
    "\n",
    "drnd18 = LightningDRN(depths=[1, 1, 2, 2, 2, 0, 1, 1], arch=\"D\", num_classes=1, in_chans=1, pooling=\"max\")\n",
    "drnd18.load_state_dict(torch.load(r\"..\\..\\tb_logs\\drnd18\\version_0\\checkpoints\\epoch=299-step=45299.ckpt\", map_location=torch.device('cpu'))['state_dict'])\n",
    "drnd18.eval()\n",
    "\n",
    "drnd18_e500 = LightningDRN(depths=[1, 1, 2, 2, 2, 0, 1, 1], arch=\"D\", num_classes=1, in_chans=1, pooling=\"max\")\n",
    "drnd18_e500.load_state_dict(torch.load(r\"..\\..\\tb_logs\\drnd18_max\\version_0\\checkpoints\\epoch=499-step=75499.ckpt\", map_location=torch.device('cpu'))['state_dict'])\n",
    "drnd18_e500.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d67a1c",
   "metadata": {},
   "source": [
    "# Deeprisk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e03e05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams=Namespace(dataset='deeprisk', trainseed=42, splitseed=42, train_frac=0.75, data_path='\\\\\\\\amc.intra\\\\users\\\\R\\\\rcklein\\\\home\\\\deeprisk\\\\weakly_supervised\\\\data', img_path='all_niftis_n=657', weak_labels_path='weak_labels_n=657.xlsx', myoseg_path='nnUnet_results\\\\nnUNet\\\\2d\\\\Task500_MyocardSegmentation\\\\predictions', seg_labels_dir=None, image_norm='global_statistic', no_roi_crop=False, include_no_myo=False, roi_crop='fixed', center_crop=224, input_size=224, rotate=0, translate=(0, 0), scale=(1, 1), shear=(0, 0, 0, 0), brightness=0, contrast=0, hflip=False, vflip=False, randomaffine_prob=0, randomcrop=False, randomerasing_probs=[])\n",
      "train transforms:\n",
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    ColorJitter(brightness=None, contrast=None, saturation=None, hue=None)\n",
      "    Normalize(mean=[0.57], std=[0.06])\n",
      "    RandomApply(\n",
      "    p=0\n",
      "    RandomAffine(degrees=[0.0, 0.0], scale=(1, 1), shear=[0.0, 0.0, 0.0, 0.0], interpolation=bilinear)\n",
      ")\n",
      ")\n",
      "val_transforms:\n",
      "Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    Normalize(mean=[0.57], std=[0.06])\n",
      ")\n",
      "Train patients: 610\n",
      "len(label_df)=243\n",
      "Validation patients: 23\n",
      "len(label_df)=19\n",
      "Test patients: 24\n",
      "len(label_df)=20\n",
      "Train data: 2427, positive: 1253\n",
      "Validation data: 170, positive: 91\n",
      "Test data: 194, positive: 86\n",
      "Train data: 2427, validation data 170\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "hparams = Namespace()\n",
    "# choose dataset\n",
    "hparams.dataset = 'deeprisk'\n",
    "# reproducability\n",
    "hparams.trainseed = 42\n",
    "hparams.splitseed = 42\n",
    "hparams.train_frac = 0.75\n",
    "# paths\n",
    "hparams.data_path = r\"\\\\amc.intra\\users\\R\\rcklein\\home\\deeprisk\\weakly_supervised\\data\"\n",
    "hparams.img_path = r\"all_niftis_n=657\"\n",
    "hparams.weak_labels_path = r\"weak_labels_n=657.xlsx\"\n",
    "hparams.myoseg_path = r\"nnUnet_results\\nnUNet\\2d\\Task500_MyocardSegmentation\\predictions\"\n",
    "hparams.seg_labels_dir = None\n",
    "# data augmentation\n",
    "hparams.image_norm = \"global_statistic\"\n",
    "hparams.no_roi_crop = False\n",
    "hparams.include_no_myo = False\n",
    "hparams.roi_crop = \"fixed\" # \"fitted\", or \"fixed\"\n",
    "hparams.center_crop = 224\n",
    "hparams.input_size = 224\n",
    "hparams.rotate = 0\n",
    "hparams.translate = (0, 0)\n",
    "hparams.scale = (1, 1)\n",
    "hparams.shear = (0, 0, 0, 0)\n",
    "hparams.brightness = 0\n",
    "hparams.contrast = 0\n",
    "hparams.hflip = False\n",
    "hparams.vflip = False\n",
    "hparams.randomaffine_prob=0\n",
    "hparams.randomcrop = False\n",
    "hparams.randomerasing_probs = []\n",
    "print(f'{hparams=}')\n",
    "\n",
    "pl.seed_everything(hparams.trainseed, workers=True)\n",
    "# prepare dataloaders\n",
    "dataset_train, dataset_val, dataset_test = load_dataset(hparams)\n",
    "print(f\"Train data: {len(dataset_train)}, validation data {len(dataset_val)}\")\n",
    "\n",
    "train_loader = DataLoader(dataset_train,\n",
    "                            batch_size=1,\n",
    "                            shuffle=False,\n",
    "                            drop_last=False,\n",
    "                            num_workers=1)\n",
    "val_loader = DataLoader(dataset_val,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb3a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6519f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cam_gen(dataloader, net, cam_methods=[], wrong_only=False):\n",
    "    n = 0\n",
    "    for batch in dataloader:\n",
    "        inputs = batch[-2]\n",
    "        labels = batch[-1]\n",
    "        bath_paths = batch[0]\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5)[:, 0].int()\n",
    "        \n",
    "        cam_batch = {}\n",
    "        cam_batch['normal_cam'] = selected_model.make_cam(inputs, select_values=\"pos_only\", upsampling=\"conv_transpose\").detach()[:,0]\n",
    "        for cam_method in cam_methods:\n",
    "            cam_batch[cam_method[0]] = cam_method[1](input_tensor=inputs, targets=None)\n",
    "        \n",
    "        for i in range(inputs.shape[0]):\n",
    "            print(f\"label:{labels[i].item()} predicted: {int(preds[i].item())} score: {torch.sigmoid(outputs[i]).detach().numpy()[0]:.3f}\")\n",
    "            fig, axs = plt.subplots(1, 2+len(cam_methods), figsize=(15, 5))\n",
    "            axs[0].imshow(inputs[i][0], cmap=\"gray\")\n",
    "            axs[0].set_title(\"Reference image\")\n",
    "            axs[1].imshow(inputs[i][0], cmap='gray')\n",
    "            axs[1].imshow(cam_batch['normal_cam'][i], cmap=\"coolwarm\", alpha=0.5, vmin=0.0, vmax=1)\n",
    "            axs[1].set_title(\"Normal CAM\")\n",
    "            for j in range(2, len(cam_methods)+2):\n",
    "                axs[j].imshow(inputs[i][0], cmap='gray')\n",
    "                axs[j].imshow(cam_batch[cam_methods[j-2][0]][i], cmap=\"coolwarm\", alpha=0.5, vmin=0.0, vmax=1)\n",
    "                axs[j].set_title(f\"{cam_methods[j-2][0]}\")\n",
    "            fig.colorbar(cm.ScalarMappable(cmap=\"coolwarm\"), ax=axs.ravel().tolist())\n",
    "            plt.show()\n",
    "            yield\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b5af6581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: target_layers is ignored in FullGrad. All bias layers will be used instead\n"
     ]
    }
   ],
   "source": [
    "selected_model = drnd18\n",
    "target_layers = [selected_model.layer8]\n",
    "gradcam = (\"gradcam\", GradCAM(model=selected_model, target_layers=target_layers))\n",
    "gradcamplusplus = (\"gradcam++\", GradCAMPlusPlus(model=selected_model, target_layers=target_layers))\n",
    "xgradcam = (\"xgradcam\", XGradCAM(model=selected_model, target_layers=target_layers))\n",
    "eigencam = (\"eigencam\", EigenCAM(model=selected_model, target_layers=target_layers))\n",
    "eigengradcam = (\"eigengradcam\", EigenGradCAM(model=selected_model, target_layers=target_layers))\n",
    "layercam = (\"layercam\", LayerCAM(model=selected_model, target_layers=target_layers))\n",
    "fullgrad = (\"fullgrad\", FullGrad(model=selected_model, target_layers=target_layers))\n",
    "\n",
    "scorecam_  = ScoreCAM(model=selected_model, target_layers=[])\n",
    "scorecam_.batch_size = 8\n",
    "scorecam = (\"scorecam\", scorecam_)\n",
    "ablationcam_ = AblationCAM(model=selected_model, target_layers=target_layers)\n",
    "ablationcam_.batch_size = 8\n",
    "ablationcam = (\"ablationcam\", ablationcam_)\n",
    "\n",
    "cam_methods = [gradcam, gradcamplusplus, xgradcam, eigencam, eigengradcam, layercam, fullgrad, scorecam, ablationcam]\n",
    "train_cam_examples = plot_cam_gen(train_loader, selected_model, cam_methods=cam_methods, wrong_only=False)\n",
    "val_cam_examples = plot_cam_gen(val_loader, selected_model, cam_methods=cam_methods, wrong_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e82e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_cam_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2333809",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(val_cam_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc1d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
